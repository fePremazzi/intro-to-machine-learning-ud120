{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entropy - measure of impurity in a bunch of examples (mede quão desigual está a amostra, quanto mais homogenea menor splits serão necessários, quanto mais impuro, mais splits serão necessários)\n",
    "Pode variar entre 0 e 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy = −∑i(pi)log2(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pi = numbers of fractions / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pslow = 0.5\n",
    "pfast = 0.5\n",
    "entropy = -((pslow*log(pslow,2))+(pfast*log(pfast,2)))\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o valor da entropia é 1 quer dizer que está divido iguamente o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Information gain = entropy(parent) - (weighted average)entropy(children).\n",
    "Decision trees try to maximize the information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saindo de \"ssff\" ele se separa em flat (f) e steep (ssf). Analisando a entropia de flat, chega a conclusão que é 0, pois ela é totalmente pura, ou seja, tudo pertence a mesma classe. Analisando agora a entropia de steep (ssf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropyFlat = 0\n",
    "pslow = 2.0/3.0\n",
    "pfast = 1.0/3.0\n",
    "entropySteep = - ((pslow*log(pslow,2))+(pfast*log(pfast,2)))\n",
    "entropySteep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31127812445913283"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infoGain = entropy(parent) - (3/4(ssf)*entropySteep + 1/4(f)*entropyFlat)\n",
    "infoGain = entropy - ((3.0/4.0)*entropySteep + (1/4)*entropyFlat)\n",
    "infoGain #information gain if splitted on GRADE column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bumpiness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saindo de \"ssff\" ele se separa em bumpy (sf) e smooth (sf). Analisando a entropia de bumpy e smooth, chega a conclusão que é 1, pois, o dataset esta dividido igualmente entre slow e fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropyBumpy = 1.0\n",
    "entropySmooth = 1.0\n",
    "infoGain = entropy - ((1.0/2.0)*entropyBumpy + (1.0/2.0)*entropySmooth)\n",
    "infoGain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias - algoritmo com um alto bias quer dizer que ele nao irá aprender nada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High varience - algoritmos muito suscetiveis a dados, ou seja, talvez ele só de um bom resulatdo se tiver um conjunto de dados muito grande, caso contrário pode ter um resultado ruim devido a falta de dados para treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ideal mesmo seria algo no meio, ir tunando o modelo até que a troca entre ganhos e perdas de bias e high variance seja boa o suficiente para que nao fique nos extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dts\n",
    "from sklearn.metrics import accuracy_score as acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting features ... \n",
      "Fitting time:  46.882 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print 'Fitting features ... '\n",
    "clf = dts(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print 'Fitting time: ',round(time()-t0,3), 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting features_test ... \n",
      "Prediction time:  0.056 s\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "print 'Predicting features_test ... '\n",
    "pred = clf.predict(features_test)\n",
    "print 'Prediction time: ',round(time()-t1,3), 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9783845278725825\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy:'\n",
    "print acc(y_true = labels_test,y_pred = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15820L, 3785L)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape\n",
    "##(X,y) = (rows, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
